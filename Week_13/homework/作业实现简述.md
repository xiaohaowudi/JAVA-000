### 作业实现简述

#### 作业要求

搭建ActiveMQ服务，基于JMS，写代码分别实现对于queue和topic的消息 生产和消费，代码提交到github

#### 实现简述

code/activemq-demo/src/main/java/com/javacamp/demo/queue 和 code/activemq-demo/src/main/java/com/javacamp/demo/topic下分别为queue和topic生产者和消费者的实现代码







#### 作业要求

搭建一个3节点Kafka集群，测试功能和性能;实现spring kafka下对kafka集群 的操作，将代码提交到github

#### 实现简述

笔者在192.168.3.144:9092 192.168.3.144:9093 192.168.3.144:9094 地址分别启动三个kafka服务器进程构成伪集群，并创建了副本因子为3，3个partition的名为cluster-topic的主题用于功能验证

topic信息如下：

```
# root @ GRH-Ubuntu in /home/grh/software_pack/kafka_2_11/kafka1 [17:28:55]
$ bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic cluster-test-topic
Topic: cluster-test-topic       PartitionCount: 3       ReplicationFactor: 3    Configs:
        Topic: cluster-test-topic       Partition: 0    Leader: 1       Replicas: 1,0,2 Isr: 1,0,2
        Topic: cluster-test-topic       Partition: 1    Leader: 0       Replicas: 0,2,1 Isr: 0,2,1
        Topic: cluster-test-topic       Partition: 2    Leader: 2       Replicas: 2,1,0 Isr: 2,1,0
```

code/kafka-spring-demo路径下的代码使用Spring-Kafka对集群的数据读写进行了测试

工程相关的配置信息如下：

```
###########【Kafka集群】###########
spring.kafka.bootstrap-servers=192.168.3.144:9092,192.168.3.144:9093,192.168.3.144:9094
###########【初始化生产者配置】###########
# 重试次数
spring.kafka.producer.retries=0
# 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
spring.kafka.producer.acks=1
# 批量大小
spring.kafka.producer.batch-size=16384
# 提交延时
spring.kafka.producer.properties.linger.ms=0
# 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
# linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了

# 生产端缓冲区大小
spring.kafka.producer.buffer-memory = 33554432
# Kafka提供的序列化和反序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 自定义分区器
# spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner

###########【初始化消费者配置】###########
# 默认的消费组ID
spring.kafka.consumer.properties.group.id=defaultConsumerGroup
# 是否自动提交offset
spring.kafka.consumer.enable-auto-commit=true

# 当kafka中没有初始offset或offset超出范围时将自动重置offset
# earliest:重置为分区中最小的offset;
# latest:重置为分区中最新的offset(消费分区中新产生的数据);
# none:只要有一个分区不存在已提交的offset,就抛出异常;
spring.kafka.consumer.auto-offset-reset=latest
# 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
spring.kafka.consumer.properties.session.timeout.ms=120000
# 消费请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=180000
# Kafka提供的序列化和反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 消费端监听的topic不存在时，项目启动会报错(关掉)
spring.kafka.listener.missing-topics-fatal=false
# 设置批量消费
# spring.kafka.listener.type=batch
# 批量消费每次最多消费多少条消息
# spring.kafka.consumer.max-poll-records=50
```

  笔者在工程中对集群中cluster-test-topic进行了读写，验证数据确实从多个物理节点的partition收发

发送端打印发送成功信息如下

```
sendMessage OK, topic=cluster-test-topic, partition=2, offset=16
sendMessage OK, topic=cluster-test-topic, partition=2, offset=17
sendMessage OK, topic=cluster-test-topic, partition=2, offset=18
sendMessage OK, topic=cluster-test-topic, partition=2, offset=19
sendMessage OK, topic=cluster-test-topic, partition=1, offset=12
sendMessage OK, topic=cluster-test-topic, partition=1, offset=13
sendMessage OK, topic=cluster-test-topic, partition=1, offset=14
2021-01-21 17:35:50.870  INFO 8443 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-defaultConsumerGroup-1, groupId=defaultConsumerGroup] Successfully joined group with generation 43
2021-01-21 17:35:50.871  INFO 8443 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-defaultConsumerGroup-1, groupId=defaultConsumerGroup] Notifying assignor about the new Assignment(partitions=[cluster-test-topic-0, cluster-test-topic-1, cluster-test-topic-2])
2021-01-21 17:35:50.873  INFO 8443 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-defaultConsumerGroup-1, groupId=defaultConsumerGroup] Adding newly assigned partitions: cluster-test-topic-1, cluster-test-topic-2, cluster-test-topic-0
sendMessage OK, topic=cluster-test-topic, partition=0, offset=12
sendMessage OK, topic=cluster-test-topic, partition=0, offset=13
sendMessage OK, topic=cluster-test-topic, partition=0, offset=14
```

接收端打印结果如下：

```
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 1 : 12 : key-0 : value-0
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 1 : 13 : key-7 : value-7
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 1 : 14 : key-8 : value-8
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 2 : 16 : key-2 : value-2
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 2 : 17 : key-3 : value-3
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 2 : 18 : key-5 : value-5
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 2 : 19 : key-6 : value-6
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 0 : 12 : key-1 : value-1
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 0 : 13 : key-4 : value-4
org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1 : 0 : 14 : key-9 : value-9
```

从打印信息看，发送端发送时候记录的partition号以及partition中的offset和接收端全部一一对应，验证了集群功能的正常













